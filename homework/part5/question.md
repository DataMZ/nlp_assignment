#### some questions and answers 

##### 1. the reasons of overfitting and underfitting
###### (1) the reasons of overfitting

-  训练集的数量级和模型的复杂度不匹配。训练集的数量级要小于模型的复杂度;
-  训练集和测试集特征分布不一致;
-  样本里面的噪音数量干扰过大, 大到模型过分记住了噪音的特征，反而忽略了真实的输入输出间的关系;
-  权值学习迭代次数足够多（Overtraining）,拟合了训练数据中的噪声和训练样例中没有代表性的特征。
```
  解决：
   1. 调小模型复杂度,使其适应自己训练集的数量级（缩小宽度和减小深度）
   2. 扩大数据集，训练集越多，过拟合的概率越小。
   3. 正则化,约束模型参数。
   4. dropout,一定概率p跳过神经元。
   5. early stopping, 它是一种迭代次数截断的方法来防止过拟合的方法。
   6. ensemble,集成学习算法可以有效减轻过拟合。
   
```

###### (2) the resons of underfitting

- 数据量太少，无法完全学习所有样本特征;
- 模型过于简单,无法满足样本复杂性;

```
  解决：
    1. 增加模型复杂度,以便适应数据特征。
    2. 减少正则化参数
    3. 增加数据量。
```